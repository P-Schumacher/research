project: 'flat_double_button_exp'
main:
  render: false
  flat_agent: true
  log: true
  minilog: true
  save_model: false
  load_model: false
  descriptor: 'flateasynotrandom_no_nstep'
  c_step: 10
  seed: 100
  offpolicy: true
  start_timesteps: 5000
  max_timesteps: 4000000
  no_seed: true
  eval_freq: 20000
  simple_env: false
  zero_obs: 0
  
  decay: false
  step_decayer:
    total_steps: 300
    init_step: ${main.c_step}
    min_step: 10

# PER can be: 
# false - Deactivated
# 1 - TD Error based prio
# 2 - Goal state distance based prio
# 3 - proportional reward based prio
# 4 - binary reward based prio 
agent:
  center_meta_goal: false
  meta_rew_scale: 0.1
  meta_noise: 0.6442
  #sub_noise: 0.0 
  goal_type: Direction
  ri_re: false
  agent_action_regularizer: 0.000
  meta_mock: false
  train_meta: true
  train_sub: true
  num_eval_episodes: 10
  smooth_goal: false
  smooth_factor: 0.7
  add_multiple_dones: false
  per: 1
  sub_per: 0
  goal_regul: 0.00
  distance_goal_regul: 0.000
  goal_every_iteration: false
  meta_model:
    ac_hidden_layers: [300, 300]
    cr_hidden_layers: [300, 300]
    clip_cr: 2.89
    clip_ac: 0.019      
    reg_coeff_ac: 4.93e-5
    reg_coeff_cr: 6.89e-5
    name: 'meta'
    discount: 0.99
    tau: 0.005
    policy_noise: 0.2
    noise_clip: 0.5
    policy_freq: 2
    ac_lr: 0.0005
    cr_lr: 0.0007
    no_candidates: 20
    zero_obs: 0
  sub_model:
    policy_freq: 1

coppeliagym:
  sim:
    scene_file: 'coppelia_scenes/kuka_double.ttt'
    render_scene_file: 'coppelia_scenes/kuka_render.ttt'
  params:
    sparse_rew: true
    action_regularizer: 0.00
    time_limit: 600
    double_buttons: true
    random_target: false
    random_eval_target: false
    reversal_time: 10000000
    touch_distance: 0.5
    minimum_dist: 0.0
    reset_on_wrong_sequence: false

  subgoals:
    ej_goal: [3, 1.0]

buffer:
  alpha: 0.9
  beta: 0.
  max_size: 200000
